{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081f8413-68b5-4494-a0ab-dbdbb62cd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "from starlette.requests import Request\n",
    "from typing import List, Optional, Any\n",
    "import torch\n",
    "import shutil\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "import json\n",
    "from typing import AsyncGenerator\n",
    "from fastapi import BackgroundTasks\n",
    "from starlette.requests import Request\n",
    "from starlette.responses import StreamingResponse, Response\n",
    "from vllm.engine.arg_utils import AsyncEngineArgs\n",
    "from vllm.engine.async_llm_engine import AsyncLLMEngine\n",
    "from vllm.sampling_params import SamplingParams\n",
    "from vllm.logger import init_logger\n",
    "from vllm.utils import random_uuid\n",
    "from ray import serve\n",
    "import vllm\n",
    "vllm_logger = init_logger(__name__)\n",
    "vllm_logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88965e0c-2918-42f4-8dec-fb5985df2a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.244.142.11\n"
     ]
    }
   ],
   "source": [
    "!echo $HOST_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742a2fbf-1605-4522-9c81-96beb3029a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\n"
     ]
    }
   ],
   "source": [
    "!echo $NCCL_DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa8b25c-9766-4796-9892-0520b652a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eth0\n"
     ]
    }
   ],
   "source": [
    "!echo $NCCL_SOCKET_IFNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6f2497-63a5-467d-9937-1d08cbc59102",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"lmsys/vicuna-13b-v1.5-16k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff183f1-45c4-41f1-b834-5dc55a5f59fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 07:56:10,182\tWARNING api.py:392 -- DeprecationWarning: `route_prefix` in `@serve.deployment` has been deprecated. To specify a route prefix for an application, pass it into `serve.run` instead.\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"ray.serve\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "@serve.deployment(num_replicas=1, ray_actor_options={\"resources\": {\"custom_worker\": 1}}, route_prefix=\"/llmapi\")\n",
    "class SnowflakeVLLMDeployment:\n",
    "    def __init__(self, **kwargs):\n",
    "        args = AsyncEngineArgs(**kwargs)\n",
    "        self.engine = AsyncLLMEngine.from_engine_args(args)\n",
    "\n",
    "    async def stream_results(self, results_generator) -> AsyncGenerator[bytes, None]:\n",
    "        num_returned = 0\n",
    "        async for request_output in results_generator:\n",
    "            text_outputs = [output.text for output in request_output.outputs]\n",
    "            assert len(text_outputs) == 1\n",
    "            text_output = text_outputs[0][num_returned:]\n",
    "            ret = {\"text\": text_output}\n",
    "            yield (json.dumps(ret) + \"\\n\").encode(\"utf-8\")\n",
    "            num_returned += len(text_output)\n",
    "\n",
    "    async def may_abort_request(self, request_id) -> None:\n",
    "        await self.engine.abort(request_id)\n",
    "\n",
    "    async def __call__(self, request: Request) -> Response:\n",
    "        request_dict = await request.json()\n",
    "        prompt = request_dict.pop(\"prompt\")\n",
    "        stream = request_dict.pop(\"stream\", False)\n",
    "        sampling_params = SamplingParams(**request_dict)\n",
    "        request_id = random_uuid()\n",
    "        results_generator = self.engine.generate(prompt, sampling_params, request_id)\n",
    "        if stream:\n",
    "            background_tasks = BackgroundTasks()\n",
    "            background_tasks.add_task(self.may_abort_request, request_id)\n",
    "            return StreamingResponse(\n",
    "                self.stream_results(results_generator), background=background_tasks\n",
    "            )\n",
    "\n",
    "        # Non-streaming case\n",
    "        final_output = None\n",
    "        async for request_output in results_generator:\n",
    "            if await request.is_disconnected():\n",
    "                # Abort the request if the client disconnects.\n",
    "                await self.engine.abort(request_id)\n",
    "                return Response(status_code=499)\n",
    "            final_output = request_output\n",
    "\n",
    "        assert final_output is not None\n",
    "        #prompt = final_output.prompt\n",
    "        #text_outputs = [prompt + output.text for output in final_output.outputs]\n",
    "        text_outputs = [output.text for output in final_output.outputs]\n",
    "        ret = {\"text\": text_outputs}\n",
    "        return Response(content=json.dumps(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e340755-b400-4ebc-89c9-6e45679de40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 07:56:10,194\tINFO worker.py:1567 -- Connecting to existing Ray cluster at address: 10.244.142.11:6379...\n",
      "2024-07-05 07:56:10,239\tINFO worker.py:1743 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m10.244.142.11:8265 \u001b[39m\u001b[22m\n",
      "[2024-07-05 07:56:10,242 I 1278 1278] logging.cc:230: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to -1\n",
      "2024-07-05 07:57:22,682\tINFO api.py:575 -- Deployed app 'llm' successfully.\n",
      "2024-07-05 07:57:22,685\tINFO router.py:286 -- Created DeploymentHandle 'coxpelah' for Deployment(name='SnowflakeVLLMDeployment', app='llm').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeploymentHandle(deployment='SnowflakeVLLMDeployment')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 07:57:22,694\tDEBUG long_poll.py:155 -- LongPollClient <ray.serve._private.long_poll.LongPollClient object at 0x7ff6da0f5db0> received updates for keys: [(LongPollNamespace.RUNNING_REPLICAS, Deployment(name='SnowflakeVLLMDeployment', app='llm')), (LongPollNamespace.DEPLOYMENT_CONFIG, Deployment(name='SnowflakeVLLMDeployment', app='llm'))].\n",
      "2024-07-05 07:57:22,695\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='SnowflakeVLLMDeployment', app='llm'): {'leszxbzd'}.\n"
     ]
    }
   ],
   "source": [
    "deployment = SnowflakeVLLMDeployment.bind(model=MODEL, tensor_parallel_size=8, seed=123)\n",
    "ray.init(address=\"auto\", log_to_driver=False)\n",
    "serve.run(target=deployment, name=\"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a58919-399e-4164-a368-9d15ed0356d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
